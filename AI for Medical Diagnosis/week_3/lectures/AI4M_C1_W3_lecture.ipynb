{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI4M Course 1 week 3 lecture notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "Click on these links to jump to that section of the notebook!\n",
    "- [Explore the data](#data)\n",
    "- [Get a subsection](#subsection)\n",
    "- [U-net model](#unet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"data\"></a>\n",
    "# Explore the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image of brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./BraTS-Data/imagesTr/BRATS_001.nii.gz\"\n",
    "image_obj = nib.load(image_path)\n",
    "type(image_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = image_obj.get_fdata()\n",
    "type(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"height, width, depth, channels\")\n",
    "image_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start at this depth to see more of the middle of the brain\n",
    "i=65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell a few times\n",
    "# to see some slices of the brain\n",
    "print(f\"depth {i}\")\n",
    "plt.imshow(image_data[:,:,i,0]);\n",
    "i +=1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label of diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = \"./BraTS-Data/labelsTr/BRATS_003.nii.gz\"\n",
    "#label = np.array(nib.load(label_nifty_file).get_fdata())\n",
    "label_obj = nib.load(label_path)\n",
    "type(label_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = label_obj.get_fdata()\n",
    "type(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"height, width, depth\")\n",
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See that all label values are either 0, 1, 2 or 3\n",
    "print(\"\"\"categories: \n",
    "0: normal \n",
    "1: edema\n",
    "2: non-enhancing tumor \n",
    "3: enhancing tumor\"\"\")\n",
    "np.unique(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label for edema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_edema = (label == 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start at this index to see more of the middle of the brain image\n",
    "i=65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell a few times\n",
    "# to see the edema labels at various slices\n",
    "print(f\"depth {i}\")\n",
    "plt.imshow(label_edema[:,:,i])\n",
    "i +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the end of this practice section.\n",
    "\n",
    "Please continue on with the lecture videos!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"subsection\"></a>\n",
    "# Get a sub-section\n",
    "\n",
    "Show how to do this for 1D arrays. the assignment will be 3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 11, 12, 13, 14, 15])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = np.array([10,11,12,13,14,15])\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_length = image.shape[0]\n",
    "image_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_length = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start index 4\n",
      "end index 7\n",
      "[14 15]\n"
     ]
    }
   ],
   "source": [
    "# run this a few times to see some valid sub-sections\n",
    "# and see when it's no longer valid\n",
    "print(f\"start index {start_i}\")\n",
    "end_i = start_i + patch_length\n",
    "print(f\"end index {end_i}\")\n",
    "sub_section = image[start_i: end_i]\n",
    "print(sub_section)\n",
    "start_i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start index 3\n",
      "end index 6\n",
      "[13 14 15]\n"
     ]
    }
   ],
   "source": [
    "# This is a valid patch\n",
    "start_i = 3\n",
    "print(f\"start index {start_i}\")\n",
    "end_i = start_i + patch_length\n",
    "print(f\"end index {end_i}\")\n",
    "sub_section = image[start_i: end_i]\n",
    "print(sub_section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest start index for which a sub section is still valid is 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"The largest start index for which \"\n",
    "      f\"a sub section is still valid is \"\n",
    "      f\"{image_length - patch_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The range of valid start indices is:\n",
      "[0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "print(f\"The range of valid start indices is:\")\n",
    "valid_start_i = [i for i in range(image_length - patch_length + 1)]\n",
    "print(valid_start_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly select a valid integer for the start index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomly selected start index 1\n"
     ]
    }
   ],
   "source": [
    "start_i = np.random.randint(image_length - patch_length + 1)\n",
    "print(f\"randomly selected start index {start_i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomly selected start index 3\n",
      "randomly selected start index 0\n",
      "randomly selected start index 1\n",
      "randomly selected start index 1\n",
      "randomly selected start index 3\n",
      "randomly selected start index 0\n",
      "randomly selected start index 1\n",
      "randomly selected start index 1\n",
      "randomly selected start index 0\n",
      "randomly selected start index 3\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    start_i = np.random.randint(image_length - patch_length + 1)\n",
    "    print(f\"randomly selected start index {start_i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the end of this practice section.\n",
    "\n",
    "Please continue on with the lecture videos!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"unet\"></a>\n",
    "## U-Net model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.engine import Input, Model\n",
    "from keras.layers import Conv3D, MaxPooling3D, UpSampling3D, Activation, BatchNormalization, PReLU, Deconvolution3D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.merge import concatenate\n",
    "K.set_image_data_format(\"channels_first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose depth\n",
    "We'll choose to make a smaller U-Net which has a full depth of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_net_depth = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input layer\n",
    "\n",
    "The shape of the input is (num_channels, height, width, depth).\n",
    "\n",
    "For the assignment, the values will be:\n",
    "- num_channels: 4\n",
    "- height: 160\n",
    "- width: 160\n",
    "- depth: 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(?, 4, 160, 160, 16) dtype=float32>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_layer = Input(shape=(4, 160, 160, 16))\n",
    "input_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the tensor shape has a '?' as the very first dimension.  This is the batch size.\n",
    "(batch_size, num_channels, height, width, depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contracting path (downward)\n",
    "We'll start with the downward path on the left side of the U-Net.  The (height,width,depth) of the 'image' gets smaller, and the number of channels increases.\n",
    "\n",
    "### Depth 0\n",
    "\n",
    "When we say 'depth' here, we're referring to the depth of the U-net and not the depth related to the height, width, depth of an image.\n",
    "\n",
    "The number of filters is specified for each depth and for each layer within that depth.\n",
    "At depth 0, for layer 0, we'll use 32 filters.\n",
    "\n",
    "The formula we're using is:\n",
    "$$filters_{i} = 32 \\times (2^{i})$$\n",
    "\n",
    "Where $i$ is the current depth.\n",
    "\n",
    "So at depth $i=0$:\n",
    "$$filters_{0} = 32 \\times (2^{0}) = 32$$\n",
    "\n",
    "#### Layer 0\n",
    "There are two convolutional layers for each depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3d convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "down_depth_0_layer_0 = Conv3D(filters=32, \n",
    "                              kernel_size=(3,3,3),\n",
    "                              padding='same',\n",
    "                              strides=(1,1,1)\n",
    "                              )(input_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can ignore the warning messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv3d_1/add:0' shape=(?, 32, 160, 160, 16) dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down_depth_0_layer_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add a relu activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'activation_1/Relu:0' shape=(?, 32, 160, 160, 16) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down_depth_0_layer_0 = Activation('relu')(down_depth_0_layer_0)\n",
    "down_depth_0_layer_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth 0\n",
    "#### Layer 1\n",
    "For layer 1 of depth 0, we'll choose 64 filters.  \n",
    "\n",
    "The formula we're using is:\n",
    "$$filters_{i} = 32 \\times (2^{i}) \\times 2$$\n",
    "\n",
    "Where $i$ is the current depth. \n",
    "- Notice the '$\\times 2$' at the end of this expression, which isn't there for layer 0.\n",
    "\n",
    "\n",
    "So at depth $i=0$:\n",
    "$$filters_{0} = 32 \\times (2^{0}) \\times 2 = 64$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'activation_2/Relu:0' shape=(?, 64, 160, 160, 16) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down_depth_0_layer_1 = Conv3D(filters=64, \n",
    "                kernel_size=(3,3,3),\n",
    "                padding='same',\n",
    "                strides=(1,1,1)\n",
    "               )(down_depth_0_layer_0)\n",
    "down_depth_0_layer_1 = Activation('relu')(down_depth_0_layer_1)\n",
    "down_depth_0_layer_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max pooling\n",
    "There is max pooling for the earlier depths (when the inputs to the layers are larger).\n",
    "\n",
    "- To decide if we include max pooling, check if the current depth of 0 is less than the U-Net's full depth of 2 minus 1.\n",
    "- The current layer depth of 0 is less than 2 minus 1.\n",
    "- In other words, 0 < 1.\n",
    "- So we'll include a max pooling layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'max_pooling3d_1/transpose_1:0' shape=(?, 64, 80, 80, 8) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down_depth_0_layer_pool = MaxPooling3D(pool_size=(2,2,2))(down_depth_0_layer_1)\n",
    "down_depth_0_layer_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth 1\n",
    "\n",
    "At depth 1, layer 0, we'll choose 64 filters\n",
    "\n",
    "The formula we're using is:\n",
    "$$filters_{i} = 32 \\times (2^{i})$$\n",
    "\n",
    "Where $i$ is the current depth.\n",
    "\n",
    "So at depth $i=1$:\n",
    "$$filters_{1} = 32 \\times (2^{1}) = 64$$\n",
    "\n",
    "#### layer 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'activation_3/Relu:0' shape=(?, 64, 80, 80, 8) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down_depth_1_layer_0 = Conv3D(filters=64, \n",
    "                kernel_size=(3,3,3),\n",
    "                padding='same',\n",
    "                strides=(1,1,1)\n",
    "               )(down_depth_0_layer_pool)\n",
    "down_depth_1_layer_0 = Activation('relu')(down_depth_1_layer_0)\n",
    "down_depth_1_layer_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer 1\n",
    "\n",
    "For layer 1 of depth 1, we'll choose 128 filters.  \n",
    "\n",
    "The formula we're using is:\n",
    "$$filters_{i} = 32 \\times (2^{i}) \\times 2$$\n",
    "\n",
    "Where $i$ is the current depth. \n",
    "- Notice the '$\\times 2$' at the end of this expression, which isn't there for layer 0.\n",
    "\n",
    "\n",
    "So at depth $i=1$:\n",
    "$$filters_{0} = 32 \\times (2^{1}) \\times 2 = 128$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'activation_4/Relu:0' shape=(?, 128, 80, 80, 8) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down_depth_1_layer_1 = Conv3D(filters=128, \n",
    "                kernel_size=(3,3,3),\n",
    "                padding='same',\n",
    "                strides=(1,1,1)\n",
    "               )(down_depth_1_layer_0)\n",
    "down_depth_1_layer_1 = Activation('relu')(down_depth_1_layer_1)\n",
    "down_depth_1_layer_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### No max pooling at depth 1\n",
    "\n",
    "When we get to the \"bottom\" of the U-net, a the last depth, we don't need to apply max pooling.\n",
    "\n",
    "- To decide if we include max pooling, check if the current depth of 1 is less than the U-Net's full depth of 2 minus 1.\n",
    "- The current layer depth of 1 is not less than 2 minus 1.\n",
    "- In other words, 1 is not less than 1.\n",
    "- So we won't include a max pooling layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanding Path (upward)\n",
    "\n",
    "Now we'll work on the expanding path of the U-Net, (going up on the right side, when viewing the diagram).  The image's (height,width,depth) gets larger in the expanding path.\n",
    "\n",
    "### Depth 0\n",
    "#### Up sampling layer 0\n",
    "\n",
    "We'll use a pool size of (2,2,2) for up sampling.\n",
    "- This is the default value for [tf.keras.layers.UpSampling3D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling3D)\n",
    "- We'll still set this parameter  explicitly for learning purposes.\n",
    "- As input to the up sampling at depth 1, we'll use the last layer of the down sampling.  In this case, it's the depth 1 layer 1.\n",
    "- Note that we're not adding any activation to this upsampling layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'up_sampling3d_1/concat_2:0' shape=(?, 128, 160, 160, 16) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up_depth_0_layer_0 = UpSampling3D(size=(2,2,2))(down_depth_1_layer_1)\n",
    "up_depth_0_layer_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate the up sampled layer with the down sampled layer\n",
    "\n",
    "Use the layers that are both at the same depth of 0.\n",
    "- up_depth_0_layer_0: shape is ?, 128, 160, 160, 16\n",
    "- depth_0_layer_1: shape is (?, 64, 160, 160, 16)\n",
    "\n",
    "- Double check that both of these layers have the same shape.\n",
    "- If they're the same shape, then they can be concatenated at axis 1 (the channel axis).\n",
    "- The height, width, depth (depth of image, not of network) is 160, 160, 16 for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"up_sampling3d_1/concat_2:0\", shape=(?, 128, 160, 160, 16), dtype=float32)\n",
      "\n",
      "Tensor(\"activation_2/Relu:0\", shape=(?, 64, 160, 160, 16), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(up_depth_0_layer_0)\n",
    "print()\n",
    "print(down_depth_0_layer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 192, 160, 160, 16) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up_depth_1_concat = concatenate([up_depth_0_layer_0,\n",
    "                                 down_depth_0_layer_1],\n",
    "                                axis=1)\n",
    "up_depth_1_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The up sampling layer has 128 channels, and the down convolution layer has 64 channels.\n",
    "- When concatenated, they have 128 + 64 = 192 channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### up convolution layer 1\n",
    "\n",
    "The number of filters for this layer will be set to the number of channels in the down convolution's layer 1 at the same depth of 0 (down_depth_0_layer_1).\n",
    "\n",
    "- The shape of down_depth_0_layer_1 is (?, 64, 160, 160, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'activation_2/Relu:0' shape=(?, 64, 160, 160, 16) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down_depth_0_layer_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The number of channels for depth_0_layer_1 is 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of filters: 64\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of filters: {down_depth_0_layer_1._keras_shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'activation_5/Relu:0' shape=(?, 64, 160, 160, 16) dtype=float32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up_depth_1_layer_1 = Conv3D(filters=64, \n",
    "                            kernel_size=(3,3,3),\n",
    "                            padding='same',\n",
    "                            strides=(1,1,1)\n",
    "                           )(up_depth_1_concat)\n",
    "up_depth_1_layer_1 = Activation('relu')(up_depth_1_layer_1)\n",
    "up_depth_1_layer_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### up convolution layer 2\n",
    "\n",
    "The number of filters will also be set to 64.\n",
    "- Again, since we're at depth 0, we look for the number of channels in the downward convolution layer at depth 0.\n",
    "- The shape of down_depth_0_layer_1 is (?, 4, 160, 160, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'activation_2/Relu:0' shape=(?, 64, 160, 160, 16) dtype=float32>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down_depth_0_layer_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The number of channels in down_depth_0_layer_1 is 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of filters: 64\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of filters: {down_depth_0_layer_1._keras_shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'activation_6/Relu:0' shape=(?, 64, 160, 160, 16) dtype=float32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up_depth_1_layer_2 = Conv3D(filters=64, \n",
    "                            kernel_size=(3,3,3),\n",
    "                            padding='same',\n",
    "                            strides=(1,1,1)\n",
    "                           )(up_depth_1_layer_1)\n",
    "up_depth_1_layer_2 = Activation('relu')(up_depth_1_layer_2)\n",
    "up_depth_1_layer_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Convolution\n",
    "\n",
    "The number of filters is set to the number of labels.\n",
    "- The number of labels is the number of categories.\n",
    "\n",
    "In this case, there are 3 labels\n",
    "\n",
    "- 1: edema\n",
    "- 2: non-enhancing tumor \n",
    "- 3: enhancing tumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv3d_9/add:0' shape=(?, 3, 160, 160, 16) dtype=float32>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_conv = Conv3D(filters=3, #3 categories \n",
    "                    kernel_size=(1,1,1),\n",
    "                    padding='valid',\n",
    "                    strides=(1,1,1)\n",
    "                    )(up_depth_1_layer_2)\n",
    "final_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation for final convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'activation_7/Sigmoid:0' shape=(?, 3, 160, 160, 16) dtype=float32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_activation = Activation('sigmoid')(final_conv)\n",
    "final_activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and compile the model\n",
    "\n",
    "In this example, we're setting the loss and metrics to options that are pre-built in Keras.  However, in the assignment, you will implement better loss funtions and metrics for evaluating the model's performance.\n",
    "- The soft dice loss\n",
    "- dice coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=input_layer, outputs=final_activation)\n",
    "model.compile(optimizer=Adam(lr=0.00001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 4, 160, 160,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 32, 160, 160, 3488        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 160, 160, 0           conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 64, 160, 160, 55360       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 160, 160, 0           conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3D)  (None, 64, 80, 80, 8 0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 64, 80, 80, 8 110656      max_pooling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 80, 80, 8 0           conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, 128, 80, 80,  221312      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128, 80, 80,  0           conv3d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_1 (UpSampling3D)  (None, 128, 160, 160 0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 192, 160, 160 0           up_sampling3d_1[0][0]            \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, 64, 160, 160, 331840      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 160, 160, 0           conv3d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)               (None, 64, 160, 160, 110656      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 160, 160, 0           conv3d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_9 (Conv3D)               (None, 3, 160, 160,  195         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 3, 160, 160,  0           conv3d_9[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 833,507\n",
      "Trainable params: 833,507\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double check your model\n",
    "\n",
    "Use a function that we've provided to create the same model, and check that the layers and the layer dimensions match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = util.unet_model_3d(depth=2,\n",
    "                                loss_function='categorical_crossentropy',\n",
    "                                metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 4, 160, 160,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_17 (Conv3D)              (None, 32, 160, 160, 3488        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 160, 160, 0           conv3d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_18 (Conv3D)              (None, 64, 160, 160, 55360       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 64, 160, 160, 0           conv3d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3D)  (None, 64, 80, 80, 8 0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_19 (Conv3D)              (None, 64, 80, 80, 8 110656      max_pooling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 64, 80, 80, 8 0           conv3d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_20 (Conv3D)              (None, 128, 80, 80,  221312      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 128, 80, 80,  0           conv3d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_3 (UpSampling3D)  (None, 128, 160, 160 0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 192, 160, 160 0           up_sampling3d_3[0][0]            \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_21 (Conv3D)              (None, 64, 160, 160, 331840      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 64, 160, 160, 0           conv3d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_22 (Conv3D)              (None, 64, 160, 160, 110656      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 64, 160, 160, 0           conv3d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_23 (Conv3D)              (None, 3, 160, 160,  195         activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 3, 160, 160,  0           conv3d_23[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 833,507\n",
      "Trainable params: 833,507\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the end of this practice section.\n",
    "\n",
    "Please continue on with the lecture videos!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
