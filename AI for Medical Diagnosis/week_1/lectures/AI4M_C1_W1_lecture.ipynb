{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI for Medicine Course 1 Week 1 lecture exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "Click on the links to jump to the desired section of this notebook!\n",
    "\n",
    "- [Image pre-processing in Keras](#image-processing)\n",
    "- [Counting Labels](#counting-labels)\n",
    "- [Weighted Loss Function](#weighted-loss)\n",
    "- [Densenet](#densenet)\n",
    "- [Patient overlap and data leakage](#patient-overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"image-processing\"></a>\n",
    "# Image Pre-preprocessing in Keras\n",
    "\n",
    "Let's use the Keras function [ImageDataGenerator](https://keras.io/preprocessing/image/) to perform data preprocessing and data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the csv file containing patient labels and file names for the chest x-rays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"nih/train-small.csv\")\n",
    "train_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardization\n",
    "\n",
    "We want to center the mean of the data around zero, and also make the standard deviation of the data equal to 1.  \n",
    "\n",
    "So we subtract the mean and divide by the standard deviation.\n",
    "\n",
    "$$\\frac{x_i - \\mu}{\\sigma}$$\n",
    "\n",
    "$\\mu$: the mean (average)  \n",
    "\n",
    "$\\sigma$: the standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize images\n",
    "image_generator = ImageDataGenerator(\n",
    "    samplewise_center=True, #Set each sample mean to 0.\n",
    "    samplewise_std_normalization= True # Divide each input by its standard deviation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[['Image','Mass']].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow from directory with specified batch size\n",
    "# and target image size\n",
    "generator = image_generator.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory=\"nih/images-small/\",\n",
    "        x_col=\"Image\", # features\n",
    "        y_col= ['Mass'], # labels\n",
    "        class_mode=\"raw\", # 'Mass' column should be in train_df\n",
    "        batch_size= 1, # images per batch\n",
    "        shuffle=False, # shuffle the rows or not\n",
    "        target_size=(320,320) # width and height of output image\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "# get the first image that was listed in the train_df dataframe\n",
    "raw_image = imageio.imread('nih/images-small/00008270_015.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(raw_image);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processed data\n",
    "Get the first image that's in the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = generator.__getitem__(0)\n",
    "plt.imshow(x[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the end of this practice section.\n",
    "\n",
    "Please continue on with the lecture videos!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"counting-labels\"></a>\n",
    "# Counting labels\n",
    "\n",
    "To avoid having class imbalance impact the loss function, we can weight the losses differently.  To choose the weights, we calculate the class frequencies.\n",
    "\n",
    "For this exercise, let's just get the count of each label.  You'll use the concepts practiced here to calculate frequencies in the assignment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels will be stored where each row is a sample (a patient), and each column is a label for a particular condition.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two patients (rows), and 3 labels (columns)\n",
    "labels_matrix = np.array(\n",
    "    [[1, 0, 0],\n",
    "     [0, 1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this sums all patients and labels\n",
    "np.sum(labels_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum for each label (column)\n",
    "np.sum(labels_matrix,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum for each patient (row)\n",
    "np.sum(labels_matrix,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decide which axis you should use in the assignment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out when the label is zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out when the label is zero\n",
    "labels_matrix == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert booleans to integers\n",
    "labels_matrix_count_zeros = (labels_matrix == 0).astype(int)\n",
    "labels_matrix_count_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the end of this practice section.\n",
    "\n",
    "Please continue on with the lecture videos!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"weighted-loss\"></a>\n",
    "# Weighted Loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array(\n",
    "        [[1],\n",
    "         [1],\n",
    "         [1],\n",
    "         [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_p = np.array([0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_n = np.array([0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9],\n",
       "       [0.9],\n",
       "       [0.9],\n",
       "       [0.9]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_1 = 0.9*np.ones(y_true.shape)\n",
    "y_pred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = 1e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted Loss Equation\n",
    "Calculate the loss for the zero-th label (column at index 0)\n",
    "\n",
    "- The loss is made up of two terms:\n",
    "    - $loss_{pos}$: we'll use this to refer to the loss where the actual label is positive (the positive examples).\n",
    "    - $loss_{neg}$: we'll use this to refer to the loss where the actual label is negative (the negative examples).  \n",
    "- Note that within the $log()$ function, we'll add a tiny positive value, to avoid an error if taking the log of zero.\n",
    "\n",
    "$$ loss^{(i)} = loss_{pos}^{(i)} + los_{neg}^{(i)} $$\n",
    "\n",
    "$$loss_{pos}^{(i)} = -1 \\times weight_{pos}^{(i)} \\times y^{(i)} \\times log(\\hat{y}^{(i)} + \\epsilon)$$\n",
    "\n",
    "$$loss_{neg}^{(i)} = -1 \\times weight_{neg}^{(i)} \\times (1- y^{(i)}) \\times log(1 - \\hat{y}^{(i)} + \\epsilon)$$\n",
    "\n",
    "$$\\epsilon = \\text{a tiny positive number}$$\n",
    "\n",
    "For this exercise, we will add up the losses from the examples.  In this week's programming assignment, you'll take the average loss over the multiple examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07902030341004104"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss from the positive predictions\n",
    "loss_1_pos = -1 * np.sum(w_p[0] * \n",
    "                y_true[:, 0] * \n",
    "                np.log(y_pred_1[:, 0] + e)\n",
    "              )\n",
    "loss_1_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7269380697459094"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss from the negative predictions\n",
    "loss_1_neg = -1 * np.sum( \n",
    "                w_n[0] * \n",
    "                (1 - y_true[:, 0]) * \n",
    "                np.log(1 - y_pred_1[:, 0] + e)\n",
    "              )\n",
    "loss_1_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8059583731559503"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_1 = loss_1_pos + loss_1_neg\n",
    "loss_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for when all predictions are 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = 0.1 * np.ones(y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7269380697459094"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss from the positive predictions\n",
    "loss_2_pos = -1 * np.sum(w_p[0] * \n",
    "                y_true[:, 0] * \n",
    "                np.log(y_pred_2[:, 0] + e)\n",
    "              )\n",
    "loss_2_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07902030341004104"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss from the negative predictions\n",
    "loss_2_neg = -1 * np.sum( \n",
    "                w_n[0] *\n",
    "                (1 - y_true[:, 0]) * \n",
    "                np.log(1 - y_pred_2[:, 0] + e)\n",
    "              )\n",
    "loss_2_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8059583731559503"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_2 = loss_2_pos + loss_2_neg\n",
    "loss_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class is imbalanced (there are 3 positive labels and 1 negative label)\n",
      "weighted loss when predictions are all 0.7 is 1.8060\n",
      "weighted loss when predictions are all 0.3 is 1.8060\n"
     ]
    }
   ],
   "source": [
    "print(\"class is imbalanced (there are 3 positive labels and 1 negative label)\")\n",
    "print(f\"weighted loss when predictions are all 0.7 is {loss_1:.4f}\")\n",
    "print(f\"weighted loss when predictions are all 0.3 is {loss_2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights are helping to give the single example of the minority (negative label) equal weight as the 3 positive examples with the positive label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the end of this practice section.\n",
    "\n",
    "Please continue on with the lecture videos!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"densenet\"></a>\n",
    "# Densenet\n",
    "\n",
    "Densenet is a convolutional network where each layer is connected to all other layers that are deeper in the network\n",
    "- The first layer is connected to the 3rd, 4th etc.\n",
    "- The second layer is connected to the 3rd, 4th, 5th etc.\n",
    "\n",
    "For a detailed explanation of Densenet, check out this post by Pablo Ruiz [\"Underestanding and visualizing DenseNets\"](https://towardsdatascience.com/understanding-and-visualizing-densenets-7f688092391a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the base pre-trained model\n",
    "base_model = DenseNet121(weights='./nih/densenet.hdf5', include_top=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View a summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are multiple convolutional layers\n",
    "layers_l = base_model.layers\n",
    "\n",
    "print(\"First 5 layers\")\n",
    "layers_l[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Last 5 layers\")\n",
    "layers_l[-6:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the convolutional layers\n",
    "conv2D_layers = [layer for layer in base_model.layers \n",
    "                if str(type(layer)).find('Conv2D') > -1]\n",
    "print(\"A couple conv2D layers\")\n",
    "conv2D_layers[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {len(conv2D_layers)} convolutional layers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The input has 3 channels\")\n",
    "base_model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The output has 1024 channels\")\n",
    "x = base_model.output\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a global spatial average pooling layer\n",
    "x_pool = GlobalAveragePooling2D()(x)\n",
    "x_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Emphysema', \n",
    "          'Hernia', \n",
    "          'Mass', \n",
    "          'Pneumonia',  \n",
    "          'Edema']\n",
    "n_classes = len(labels)\n",
    "print(f\"In this example, we want our model to identify {n_classes} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and a logistic layer\n",
    "predictions = Dense(n_classes, activation=\"sigmoid\")(x_pool)\n",
    "print(\"Predictions have {n_classes} units, one for each class\")\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy')\n",
    "# we'll customize the loss function in the assignment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the end of this practice section.\n",
    "\n",
    "Please continue on with the lecture videos!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"patient-overlap\"></a>\n",
    "# Patient Overlap and Data Leakage\n",
    "\n",
    "Patient overlap in medical data is a general problem called **data leakage**.  To identify patient overlap, check to see if a patient's ID appears in both the train set and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_train = [0, 1, 2, 0, 1, 2]\n",
    "ids_valid = [2, 3, 4, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_train_set = set(ids_train)\n",
    "ids_train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_valid_set = set(ids_valid)\n",
    "ids_valid_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_overlap = ids_train_set.intersection(ids_valid_set)\n",
    "patient_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(patient_overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The patient ID '2' appears in both the train set and valid set!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the end of this practice section.\n",
    "\n",
    "Please continue on with the lecture videos!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
